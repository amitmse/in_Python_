Covariance:
	- It refers to the measure of how two variables will change (directional relationship) when they are compared to each other
	- It measures the Variance between two variables

ANOVA:
	Known as analysis of variance, is used to compare multiple (three or more) samples with a single test 
	i.e. all sample means are equal
	
Probability Distribution:
	- Probability distributions describe what we think the probability of each outcome is.
	- They come in many shapes, but in only one size: probabilities in a distribution always add up to 1.
	- A probability distribution is a function that assigns to each event a number in [0,1] which is 
	  the probability that this event occurs.
	- A statistical model is a set of probability distributions. We assume that the observations are generated 
	  from one of these distributions.
	- Chart: Horizontal axis set of possible numeric outcomes. Vertical axis probability of outcomes.
	Example: 
		- Flipping a fair coin has two outcomes: it lands heads or tails. 
		  Before the flip, we believe there’s a 0.5 probability, of heads and same for tails. 
		  That’s a probability distribution over the two outcomes of the flip (Bernoulli distribution).
	
	Bernoulli distribution:
		- The Bernoulli PDF has two lines of equal height, representing the two equally-probable outcomes
		  of 0 and 1 at either end.
		- Bernoulli Distribution is a special case of Binomial Distribution with a single trial
		Example: 
			- Flipping a fair coin
		
	Uniform distribution:
		- Many equally-likely outcomes (Bernoulli):the uniform distribution, characterized by its flat PDF. 
		- It can be defined for any number of outcomes or even as a continuous distribution.
		Example: 
			- Imagine rolling a fair die. The outcomes 1 to 6 are equally likely.
	
	Binomial distribution:
		The binomial distribution may be thought of as the sum of outcomes of things that follow a Bernoulli distribution.
		Example: 
			- Toss a fair coin 20 times; how many times does it come up heads? This count is an outcome that follows 
			  the binomial distribution. Each flip is a Bernoulli-distributed outcome. Converted to binomial 
			  distribution when counting the number of successes, where each flip is independent and has 
			  the same probability of success.
			
			- Imagine an urn with equal numbers of white and black balls. Draw a ball and note whether it is black, 
			  then put it back and Repeat this process. How many times black ball was drawn? 
			  This count also follows a binomial distribution.
			
	Hyper-Geometric distribution:
		Example: 
			- This is the distribution of that same count if the balls were drawn without replacement instead. 
			  Undeniably it’s a cousin to the binomial distribution, but not the same, because the probability 
			  of success changes as balls are removed. 
			- If the number of balls is large relative to the number of draws, the distributions are similar
			  because the chance of success changes less with each draw.
		
	Poisson distribution:
		- Simialr to the binomial distribution, the Poisson distribution is the distribution of a 
		  count - the count of times something happened. 
		- The Poisson distribution is when trying to count events over a time given the continuous rate of 
		  events occurring
		- Poisson Distribution is a limiting case of binomial distribution.
		Example:
			- Packets arrive at routers, or customers arrive at a store, or things wait in some kind of queue Count 
			  of customers calling a support hot-line each minute doesn't follow binomial/Bernoulli but Poisson.
		
	Geometric distribution:
		- If the binomial distribution is “How many successes?” then the geometric distribution is
		  “How many failures until a success?”
		Example:
			- From simple Bernoulli trials arises another distribution. How many times does a flipped coin 
			  come up tails before it first comes up heads? This count of tails follows a geometric distribution.

	Negative Binomial distribution:
		- It's a simple generalization. It’s the number of failures until r successes have occurred,not just 1.
		Example: 
		
	Exponential distribution:
		- The exponential distribution is one of the widely used continuous distributions. 
		- It is often used to model the time elapsed between events.
		- The exponential distribution should come to mind when thinking of "time until event", maybe "time until failure".
		- Exponential distribution is widely used for survival analysis. From the expected life of a machine to 
		  the expected life of a human, exponential distribution successfully delivers the result.
		- There is a strong relationship between the Poisson distribution and the Exponential distribution. 
		Example: 
			- let’s say a Poisson distribution models the number of births in a given time period. 
			  The time in between each birth can be modeled with an exponential distribution.
	
	Weibull:
		- Weibull distribution can model increasing (or decreasing) rates of failure over time. 
		- The exponential is merely a special case.

	Normal Distribution:
		- The sum of Bernoulli trials follows a binomial distribution, and as the number of trials increases, 
		  that binomial distribution becomes more like the normal distribution. 
		- Its cousin the hyper-geometric distribution does too. 
		- The Poisson distribution—an extreme form of binomial—also approaches the normal distribution as 
		  the rate parameter increases.
		- The mean, median and mode of the distribution coincide.
		- The curve of the distribution is bell-shaped and symmetrical about the line x=μ.
		- Normal distribution is another limiting form of binomial distribution.
		- The standard normal distribution (also known as the Z distribution) is the normal distribution 
		  with a mean of zero and a variance of one.
	
	Z-test:
		- The sample is assumed to be normally distributed. A z-score is calculated with population 
		  parameters such as "population mean" and "population standard deviation" and is used to validate 
		  a hypothesis that the sample drawn belongs to the same population. Sample mean is same as the population mean.

	t /Student  Distribution:
		- The t test tells how significant the differences between groups are. A t-test is used to compare the mean of 
		  two given samples.
		- A t-test is used when the population mean and population standard deviation are unknown.
		- Independent samples t-test which compares mean for two groups. t test for equality of 
		  population mean when variance is same.
		- Before t test, F test is required for equality for variance.
		- One sample t-test which tests the mean of a single group against a known mean.
		- Test the significance of regression coefficient. 
		- Example:
			- A very simple example: Let’s say you have a cold and you try a naturopathic remedy. 
			  Your cold lasts a couple of days. The next time you have a cold, you buy an over-the-counter 
			  pharmaceutical and the cold lasts a week. You survey your friends and they all tell you that 
			  their colds were of a shorter duration (an average of 3 days) when they took the homeopathic remedy. 
			  What you really want to know is, are these results repeatable? A t test can tell you by comparing
			  the means of the two groups and letting you know the probability of those results happening by chance.

			- Paired sample t-test which compares means from the same group at different times. 
			  Choose the paired t-test if you have two measurements on the same item, person or thing
			  
	Chi-Squared Distribution :
		- Tests for the strength of the association between two categorical variables. Chi Square lets you know whether 
		  two groups have significantly different opinions, which makes it a very useful statistic for survey research.
		- Population mean is known and test the variance of normal distributed. chi squared distribution is the square 
		  of a normal distribution.
		- The chi-squared distribution is used primarily in hypothesis testing:
			- Goodness of fit test, which determines if a sample matches the population 
				(does a coin tossed 20 times turn up 10 heads and 10 tails?)
			- A chi-square fit test for two independent variables is used to compare two variables in a contingency table 
				to check if the data fits
			- Chi-squared test of independence in contingency tables (is there a relationship between gender and salary?)
			- Likelihood-ratio test for nested models
			- Log-rank test in survival analysis
			- Cochran–Mantel–Haenszel test for stratified contingency tables

	Likelihood-ratio :
		- This test assesses the goodness of fit of two competing statistical models based on the ratio of their likelihoods
	
	F-test:
		- F-test of equality of variances is a test for the null hypothesis that two normal populations have the same variance. 
	
		- It is most often used when comparing statistical models that have been fitted to a data set, 
		  in order to identify the model that best fits the population from which the data were sampled. 
		  "F-tests" mainly arise when the models have been fitted to the data using least squares.

-----------------------------------------------------------------------------------------------------------------------------------

https://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/
https://www.johndcook.com/blog/distribution_chart/

-----------------------------------------------------------------------------------------------------------------------------------
